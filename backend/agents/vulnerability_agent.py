"""Vulnerability Discovery Agent — Deep AI-driven vulnerability analysis."""

import json
from typing import Any, Dict, List

from agents.base_agent import BaseAgent
from utils.llm_client import get_llm_response
from db.redis_client import update_scan_progress

SYSTEM_PROMPT = """You are an elite security vulnerability researcher with 15+ years of experience. You discover vulnerabilities that automated tools miss.

Analyze the provided code with focus on:
1. **SQL Injection** — String concatenation in queries, ORM misuse, raw queries
2. **Cross-Site Scripting (XSS)** — Reflected, stored, DOM-based
3. **Authentication Flaws** — Weak password handling, missing auth checks, session issues
4. **Authorization Flaws** — IDOR, privilege escalation, missing access controls
5. **Hardcoded Secrets** — API keys, passwords, tokens in source
6. **Logic Flaws** — Race conditions, TOCTOU, business logic bypasses
7. **Insecure Deserialization** — Pickle, YAML, JSON parsing issues
8. **Command Injection** — OS command execution with user input
9. **Path Traversal** — File access without proper sanitization
10. **Server-Side Request Forgery (SSRF)** — Unvalidated URL fetching
11. **Cryptographic Issues** — Weak algorithms, improper key management
12. **Information Disclosure** — Error messages, debug info, stack traces

For each vulnerability, provide:
- Exact file and line numbers
- Clear exploitation scenario
- Severity assessment with reasoning

Output valid JSON:
{
    "vulnerabilities": [
        {
            "title": "...",
            "vulnerability_type": "SQL Injection|XSS|Auth Flaw|...",
            "severity": "Critical|High|Medium|Low",
            "description": "Detailed description of the vulnerability",
            "file_path": "...",
            "line_start": N,
            "line_end": N,
            "vulnerable_code": "exact vulnerable code snippet",
            "exploitation_scenario": "How an attacker would exploit this",
            "cwe_id": "CWE-XXX",
            "confidence": 0-100,
            "risk_score": 0-100,
            "exploitability": 0-100,
            "impact": 0-100
        }
    ],
    "summary": "Overall vulnerability assessment"
}"""


class VulnerabilityDiscoveryAgent(BaseAgent):
    name = "vulnerability_discovery_agent"
    description = "Deep AI-driven vulnerability discovery"

    async def run(self, state: Dict[str, Any]) -> Dict[str, Any]:
        project_id = state.get("project_id", "")
        files = state.get("files", [])
        recon = state.get("recon_results", {})
        static_results = state.get("static_analysis_results", {})

        await self.log(project_id, "Starting deep vulnerability analysis")
        await update_scan_progress(project_id, "analysis", self.name, 0.1, "Deep vulnerability scanning...")

        # Focus on high-risk files identified by recon
        high_risk_files = self._prioritize_files(files, recon)
        await self.log(project_id, f"Analyzing {len(high_risk_files)} high-priority files")

        all_vulns: List[Dict] = []

        # Analyze in batches
        batch_size = 5
        for i in range(0, len(high_risk_files), batch_size):
            batch = high_risk_files[i:i + batch_size]
            progress = 0.1 + (0.7 * (i / max(len(high_risk_files), 1)))
            await update_scan_progress(project_id, "analysis", self.name, progress, f"Analyzing batch {i // batch_size + 1}...")

            batch_context = self._build_batch_context(batch, state.get("ast_data", []))
            
            user_prompt = f"""Perform deep security analysis on these files:

{batch_context}

RECON CONTEXT:
Entry Points: {json.dumps(recon.get('entry_points', [])[:10], default=str)}
Sensitive Components: {json.dumps(recon.get('sensitive_components', [])[:10], default=str)}

DETERMINISTIC ANALYSIS (Already found by static tools):
We already found {len(state.get('vulnerabilities', []))} vulnerabilities via static deterministic layers. Focus on COMPLEX LOGIC FLAWS, RACE CONDITIONS, AND AI-LEVEL DEEP ANALYSIS. Do NOT just repeat syntax errors. 

Find ALL vulnerabilities including subtle logic flaws and security anti-patterns."""

            try:
                response = await get_llm_response(SYSTEM_PROMPT, user_prompt, json_mode=True, max_tokens=4096)
                batch_results = json.loads(response)
                all_vulns.extend(batch_results.get("vulnerabilities", []))
            except Exception as e:
                error_msg = f"Batch analysis error: {str(e)}"
                print(f"[VULN AGENT] {project_id}: {error_msg}")
                await self.log(project_id, error_msg, "warning")
                # Continue with empty batch - don't fail entire scan

        # Merge with static analysis findings
        static_findings = static_results.get("findings", [])
        for finding in static_findings:
            if not finding.get("is_false_positive", False):
                # Convert to vulnerability format
                all_vulns.append({
                    "title": finding.get("title", ""),
                    "vulnerability_type": finding.get("type", "Unknown"),
                    "severity": finding.get("severity", "Medium"),
                    "description": finding.get("description", ""),
                    "file_path": finding.get("file_path", ""),
                    "line_start": finding.get("line_start", 0),
                    "line_end": finding.get("line_end", 0),
                    "vulnerable_code": finding.get("code_snippet", ""),
                    "cwe_id": finding.get("cwe_id", ""),
                    "confidence": finding.get("confidence", 50),
                    "risk_score": 50,
                    "exploitability": 50,
                    "impact": 50,
                })

        # Deduplicate
        all_vulns = self._deduplicate(all_vulns)

        await self.save_output(project_id, {"vulnerabilities": all_vulns})
        await self.log(project_id, f"Vulnerability scan complete: {len(all_vulns)} vulnerabilities found", "success")
        await update_scan_progress(project_id, "analysis", self.name, 1.0, "Vulnerability discovery complete")

        state["vulnerabilities"] = all_vulns
        return state

    def _prioritize_files(self, files: List[Dict], recon: Dict) -> List[Dict]:
        """Prioritize files based on recon results."""
        risk_files = set()
        for ep in recon.get("entry_points", []):
            risk_files.add(ep.get("file", ""))
        for sc in recon.get("sensitive_components", []):
            risk_files.add(sc.get("file", ""))
        for ds in recon.get("data_stores", []):
            risk_files.add(ds.get("file", ""))

        # Put high-risk files first, then the rest
        prioritized = []
        rest = []
        for f in files:
            if f["file_path"] in risk_files:
                prioritized.append(f)
            else:
                rest.append(f)

        return prioritized + rest[:15]  # Limit total files

    def _build_batch_context(self, batch: List[Dict], ast_data: List[Dict]) -> str:
        parts = []
        for f in batch:
            content = f.get("content", "")
            filepath = f.get("file_path", "")
            # Add AST context if available
            ast_info = next((a for a in ast_data if a.get("filename") == filepath), {})
            functions = [fn.get("name") for fn in ast_info.get("functions", []) if "name" in fn]
            func_str = f" [AST Functions: {', '.join(functions)}]" if functions else ""
            
            # Add line numbers for precise referencing
            numbered_lines = []
            for i, line in enumerate(content.split("\n"), 1):
                numbered_lines.append(f"{i:4d} | {line}")
            numbered = "\n".join(numbered_lines[:400])  # Cap at 400 lines per file
            parts.append(f"=== FILE: {filepath} (Language: {f.get('language', 'unknown')}, Lines: {len(content.splitlines())}){func_str} ===\n{numbered}")
        return "\n\n".join(parts)

    def _deduplicate(self, vulns: List[Dict]) -> List[Dict]:
        """Remove duplicate vulnerabilities."""
        seen = set()
        unique = []
        for v in vulns:
            key = (v.get("file_path", ""), v.get("line_start", 0), v.get("title", ""))
            if key not in seen:
                seen.add(key)
                unique.append(v)
        return unique
